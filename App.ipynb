{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e69d3ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:45:26.064540Z",
     "start_time": "2023-07-23T16:45:26.061270Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference/tree/main/data\n",
    "# https://towardsdatascience.com/running-llama-2-on-cpu-inference-for-document-q-a-3d636037a3d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bdc01a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:45:27.474611Z",
     "start_time": "2023-07-23T16:45:26.631598Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0372b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:45:30.179640Z",
     "start_time": "2023-07-23T16:45:27.475862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load PDF file from data path\n",
    "loader = DirectoryLoader('data/',\n",
    "                         glob=\"*.pdf\",\n",
    "                         loader_cls=PyPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3dd558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:45:30.226940Z",
     "start_time": "2023-07-23T16:45:30.181302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split text from PDF into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                               chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ae3ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:46:04.103922Z",
     "start_time": "2023-07-23T16:45:30.227960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reza/.pyenv/versions/3.10.0/envs/paper-chat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                   model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# Build and persist FAISS vector store\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "vectorstore.save_local('vectorstore/db_faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1508bbe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:46:04.107503Z",
     "start_time": "2023-07-23T16:46:04.105806Z"
    }
   },
   "outputs": [],
   "source": [
    "qa_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d939449b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:46:04.140452Z",
     "start_time": "2023-07-23T16:46:04.108228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config: https://github.com/marella/ctransformers#config\n",
    "# Download model from https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main\n",
    "\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "# Local CTransformers wrapper for Llama-2-7B-Chat\n",
    "llm = CTransformers(model='models/llama-2-7b-chat.ggmlv3.q8_0.bin', # Location of downloaded GGML model\n",
    "                    model_type='llama', # Model type Llama\n",
    "                    config={'max_new_tokens': 1000,\n",
    "                            'temperature': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f0f9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:46:46.952522Z",
     "start_time": "2023-07-23T16:46:46.938436Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Wrap prompt template in a PromptTemplate object\n",
    "def set_qa_prompt():\n",
    "    prompt = PromptTemplate(template=qa_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Build RetrievalQA object\n",
    "def build_retrieval_qa(llm, prompt, vectordb):\n",
    "    dbqa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type='stuff',\n",
    "                                       retriever=vectordb.as_retriever(search_kwargs={'k':2}),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={'prompt': prompt})\n",
    "    return dbqa\n",
    "\n",
    "\n",
    "# Instantiate QA object\n",
    "def setup_dbqa():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "    vectordb = FAISS.load_local('vectorstore/db_faiss', embeddings)\n",
    "    qa_prompt = set_qa_prompt()\n",
    "    dbqa = build_retrieval_qa(llm, qa_prompt, vectordb)\n",
    "\n",
    "    return dbqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "face6e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:46:48.395753Z",
     "start_time": "2023-07-23T16:46:48.157334Z"
    }
   },
   "outputs": [],
   "source": [
    "dbqa = setup_dbqa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b718dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:47:22.166885Z",
     "start_time": "2023-07-23T16:47:07.416753Z"
    }
   },
   "outputs": [],
   "source": [
    "response = dbqa({'query': \"test dulu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f0fa577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:47:22.171902Z",
     "start_time": "2023-07-23T16:47:22.168470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'test dulu',\n",
       " 'result': 'The break-even test results submitted in March 2022 were positive, so no further action is required until the next break-even test.',\n",
       " 'source_documents': [Document(page_content='test result submitted in March 2022 was positive.', metadata={'source': 'data/manu-20f-2022-09-24.pdf', 'page': 61}),\n",
       "  Document(page_content='Rules was submitted in March 2022, based on our fiscal year 2021 and fiscal year 2020 audited financialstatements. The break-even test is based on a club’s audited pre-tax earnings. If the break-even test resultsare positive, no further action is required until the next break-even test. If the initial test is negative, a club isre-tested, using the UEFA definition of “adjusted earnings before tax,” which allows credit for depreciationof tangible fixed assets and expenditure on youth development', metadata={'source': 'data/manu-20f-2022-09-24.pdf', 'page': 61})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e725416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:47:22.176049Z",
     "start_time": "2023-07-23T16:47:22.173034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The break-even test results submitted in March 2022 were positive, so no further action is required until the next break-even test.\n",
      "==================================================\n",
      "\n",
      "Source Document 1\n",
      "\n",
      "Source Text: test result submitted in March 2022 was positive.\n",
      "Document Name: data/manu-20f-2022-09-24.pdf\n",
      "Page Number: 61\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source Document 2\n",
      "\n",
      "Source Text: Rules was submitted in March 2022, based on our fiscal year 2021 and fiscal year 2020 audited financialstatements. The break-even test is based on a club’s audited pre-tax earnings. If the break-even test resultsare positive, no further action is required until the next break-even test. If the initial test is negative, a club isre-tested, using the UEFA definition of “adjusted earnings before tax,” which allows credit for depreciationof tangible fixed assets and expenditure on youth development\n",
      "Document Name: data/manu-20f-2022-09-24.pdf\n",
      "Page Number: 61\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nAnswer: {response[\"result\"]}')\n",
    "print('='*50) # Formatting separator\n",
    "source_docs = response['source_documents']\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f'\\nSource Document {i+1}\\n')\n",
    "    print(f'Source Text: {doc.page_content}')\n",
    "    print(f'Document Name: {doc.metadata[\"source\"]}')\n",
    "    print(f'Page Number: {doc.metadata[\"page\"]}\\n')\n",
    "    print('='* 50) # Formatting separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c1876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a6c0de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:47:34.292742Z",
     "start_time": "2023-07-23T16:47:22.177863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The minimum guarantee payable by adidas over the term of the agreement with us is £750 million, subject to certain adjustments.\n",
      "==================================================\n",
      "\n",
      "Source Document 1\n",
      "\n",
      "Source Text: The minimum guarantee payable by adidas over the term of our agreement with them is equal to\n",
      "Document Name: data/manu-20f-2022-09-24.pdf\n",
      "Page Number: 84\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source Document 2\n",
      "\n",
      "Source Text: Pursuant to our contract with adidas, which began on 1 August 2015, the minimum guarantee payable\n",
      "by adidas over the 10-year term of the agreement is equal to £750 million, subject to certain adjustments.See “Item 4. Information on the Company—Revenue Sectors—Commercial—Retail, Merchandising,Apparel & Product Licensing” for additional information regarding our agreement with adidas.\n",
      "We also maintain a mixture of long-term debt and capacity under our revolving facilities in order to\n",
      "Document Name: data/manu-20f-2022-09-24.pdf\n",
      "Page Number: 74\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "response = dbqa({'query': \"How much is the minimum guarantee payable by adidas?\"})\n",
    "\n",
    "print(f'\\nAnswer: {response[\"result\"]}')\n",
    "print('='*50) # Formatting separator\n",
    "\n",
    "source_docs = response['source_documents']\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f'\\nSource Document {i+1}\\n')\n",
    "    print(f'Source Text: {doc.page_content}')\n",
    "    print(f'Document Name: {doc.metadata[\"source\"]}')\n",
    "    print(f'Page Number: {doc.metadata[\"page\"]}\\n')\n",
    "    print('='* 50) # Formatting separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89d830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7d1057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:48:13.733194Z",
     "start_time": "2023-07-23T16:47:57.284009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Embeddings are data that has been transformed into n-dimensional matrices for use in deep learning computations. They represent individual elements in a dataset as vectors or tensors, which can be easily processed by deep neural networks.\n",
      "==================================================\n",
      "\n",
      "Source Document 1\n",
      "\n",
      "Source Text: them explicitly from the beginning.\n",
      "As a general definition, embeddings are data that has been transformed\n",
      "into n-dimensional matrices for use in deep learning computations. The\n",
      "process of embedding (as a verb):\n",
      "•Transforms multimodal input into representations that are easier to\n",
      "perform intensive computation on, in the form of vectors , tensors, or\n",
      "graphs [ 51]. For the purpose of machine learning, we can think of\n",
      "vectors as a list (or array) of numbers.\n",
      "Document Name: data/embeddings.pdf\n",
      "Page Number: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source Document 2\n",
      "\n",
      "Source Text: What do embeddings actually look like? Here is one single embedding,\n",
      "also called a vector , in three dimensions . We can think of this as a repre-\n",
      "sentation of a single element in our dataset. For example, this hypothetical\n",
      "embedding represents a single word \"fly\", in three dimensions. Generally, we\n",
      "represent individual embeddings as row vectors.\n",
      "\u0002\n",
      "1 4 9\u0003\n",
      "(1)\n",
      "And here is a tensor , also known as a matrix3, which is a multidimensional\n",
      "Document Name: data/embeddings.pdf\n",
      "Page Number: 5\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "response = dbqa({'query': \"What is embeddings?\"})\n",
    "print(f'\\nAnswer: {response[\"result\"]}')\n",
    "print('='*50) # Formatting separator\n",
    "\n",
    "source_docs = response['source_documents']\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f'\\nSource Document {i+1}\\n')\n",
    "    print(f'Source Text: {doc.page_content}')\n",
    "    print(f'Document Name: {doc.metadata[\"source\"]}')\n",
    "    print(f'Page Number: {doc.metadata[\"page\"]}\\n')\n",
    "    print('='* 50) # Formatting separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18b217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef6dfa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:49:10.165202Z",
     "start_time": "2023-07-23T16:48:48.499435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Word2Vec is a technique for converting words in a text corpus into numerical vectors that capture their semantic meaning. The vectors are learned based on the context in which the words appear, so similar words will be close together in the vector space. Word2Vec models use a shallow neural network to learn the vector representations from large amounts of text data. The key insight behind Word2Vec is that the vector representation of a word can be learned by predicting the context words around it. This allows the model to capture subtle nuances in meaning between similar words, such as \"car\" and \"automobile\".\n",
      "==================================================\n",
      "\n",
      "Source Document 1\n",
      "\n",
      "Source Text: relationship between them. For example, “The dog chased the cat” and “the\n",
      "cat chased the dog” would have the same distance in the vector space, even\n",
      "though they’re two completely different sentences.\n",
      "Word2Vec is a family of models that has several implementations, each\n",
      "of which focus on transforming the entire input dataset into vector represen-\n",
      "42\n",
      "Document Name: data/embeddings.pdf\n",
      "Page Number: 41\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source Document 2\n",
      "\n",
      "Source Text: ence. But, since we’re just learning about them, we’d like to see a bit more\n",
      "explicitly how they work, and PyTorch, although it does not have a native\n",
      "implementation of Word2Vec, lets us see the inner workings a bit more clearly.\n",
      "To model our problem in PyTorch, we’ll use the same approach as with\n",
      "any problem in machine learning:\n",
      "• Inspect and clean our input data.\n",
      "•Build the layers of our model. (For traditional ML, we’ll have only\n",
      "one)\n",
      "Document Name: data/embeddings.pdf\n",
      "Page Number: 43\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "response = dbqa({'query': \"Explain word2vec to me\"})\n",
    "print(f'\\nAnswer: {response[\"result\"]}')\n",
    "print('='*50) # Formatting separator\n",
    "\n",
    "source_docs = response['source_documents']\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f'\\nSource Document {i+1}\\n')\n",
    "    print(f'Source Text: {doc.page_content}')\n",
    "    print(f'Document Name: {doc.metadata[\"source\"]}')\n",
    "    print(f'Page Number: {doc.metadata[\"page\"]}\\n')\n",
    "    print('='* 50) # Formatting separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd4aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a644347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
